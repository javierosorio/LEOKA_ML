{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**File: train_LEOKA_hierarchical_multiclass.ipynb**\\\n",
        "Author: Amber Converse\\\n",
        "Purpose: This file trains a multi-label classification sequential neural network on labeled stories from LEOKA using ConfliBERT English to generate features."
      ],
      "metadata": {
        "id": "uyfCvgcTNqea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOzHwgtFNpYr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing\n",
        "\n",
        "# If True, data is already processed into text\\tlabel format.\n",
        "# If False, data is processed from a JSON from Label Studio and exported as a tsv.\n",
        "# Note: For JSON format, it is assumed a train/dev/test split has not been done.\n",
        "from_tsv = False\n",
        "\n",
        "json_files = []\n",
        "train_files = []\n",
        "dev_files = []\n",
        "test_files = []\n",
        "\n",
        "def read_tsvs(tsvs):\n",
        "  text_label = []\n",
        "  for tsv in tsvs:\n",
        "    with open(tsv, 'r') as tsv_file:\n",
        "      for line in tsv_file:\n",
        "        line = row.split('\\t')\n",
        "        text_label.append([line[0], ast.literal_eval(line[1])])\n",
        "    return text_label\n",
        "\n",
        "def read_jsons(jsons):\n",
        "  text_labels = []\n",
        "  for json in jsons:\n",
        "    with open(json, 'r') as json_file:\n",
        "\n",
        "      tasks = json.load(json_file)\n",
        "\n",
        "      total_tasks = len(tasks)\n",
        "      tasks_taken = 0\n",
        "\n",
        "      labels = []\n",
        "      for task in tasks:\n",
        "        task_annotations = []\n",
        "        for annotation in task[\"annotations\"]:\n",
        "          if annotation[\"type\"] == \"taxonomy\":\n",
        "            cur_labels = []\n",
        "            for label in annotation[\"value\"][\"taxonomy\"]:\n",
        "              cur_labels.append((labe[0],label[1]))\n",
        "            task_annotations.append()\n",
        "        if len({set(task_annotation) for task_annotation in task_annotations}) == 1:\n",
        "          labels.append([task[\"text\"], task_annotations[0]])\n",
        "          tasks_taken += 1\n",
        "\n",
        "      print(f\"{tasks_taken/total_tasks*100}% of tasks accepted from json\")\n",
        "\n",
        "      text_labels += labels\n",
        "    return text_labels\n",
        "\n",
        "def separate_labels(labels):\n",
        "  '''\n",
        "  Separate labels into a dictionary with the format:\n",
        "\n",
        "  {first-order label:\n",
        "      {\n",
        "        second-order label: indices (an array of indices with this label)\n",
        "        indices (an array of indices with this label)\n",
        "      }\n",
        "  }\n",
        "\n",
        "  returns the dictionary\n",
        "  '''\n",
        "  labels_dict = {}\n",
        "  for i, annotations in enumerate(labels):\n",
        "    for annotation in annotations:\n",
        "      first_order = annotation[0]\n",
        "      if not first_order in labels_dict:\n",
        "        labels_dict[first_order] = {\"indices\":[]}\n",
        "      labels_dict[first_order][\"indices\"].append(i)\n",
        "      if len(annotation) > 1:\n",
        "        second_order = annotation[1]\n",
        "        if not second_order in labels_dict[first_order]:\n",
        "          labels_dict[first_order][second_order] = []\n",
        "        labels_dict[first_order][second_order].append(i)\n",
        "  return labels_dict\n",
        "\n",
        "if from_tsv:\n",
        "  train_texts, train_labels = zip(*read_tsvs(train_files))\n",
        "  dev_texts, dev_labels = zip(*read_tsvs(train_files))\n",
        "  test_texts, test_labels = zip(*read_tsvs(train_files))\n",
        "else:\n",
        "  texts, labels = zip(*read_jsons(json_files))\n",
        "\n",
        "  train_texts, train_labels, test_texts, test_labels = train_test_split(texts,labels, random_state=4096,test_size=0.5, shuffle=True)\n",
        "  dev_texts, dev_labels, test_texts, test_labels = train_test_split(test_texts,test_labels, random_state=4096,test_size=0.4, shuffle=True)"
      ],
      "metadata": {
        "id": "K-glSJd4PELi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}